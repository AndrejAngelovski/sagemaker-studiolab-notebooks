{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f57065-0b4e-438c-9fb1-9c8a045dba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx[default]\n",
      "  Downloading networkx-2.8-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from networkx[default]) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from networkx[default]) (1.8.0)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from networkx[default]) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from networkx[default]) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.4->networkx[default]) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.4->networkx[default]) (4.33.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.4->networkx[default]) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.4->networkx[default]) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.4->networkx[default]) (9.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.4->networkx[default]) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.4->networkx[default]) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=1.3->networkx[default]) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->networkx[default]) (1.16.0)\n",
      "Installing collected packages: networkx\n",
      "Successfully installed networkx-2.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx[default]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2015fc0f-4439-4192-8919-b7d0fc50b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "default_edge_color = 'gray'\n",
    "default_node_color = '#407cc9'\n",
    "enhanced_node_color = '#f5b042'\n",
    "enhanced_edge_color = '#cc2f04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e18f86-20ed-4d8b-96b6-f84736aafba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = pd.read_csv('lab_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf10d549-6282-4c73-b9fe-bc108e7bd872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_id': dtype('int64'),\n",
       " 'subject_id': dtype('int64'),\n",
       " 'hadm_id': dtype('float64'),\n",
       " 'itemid': dtype('int64'),\n",
       " 'charttime': dtype('O'),\n",
       " 'value': dtype('O'),\n",
       " 'valuenum': dtype('float64'),\n",
       " 'valueuom': dtype('O'),\n",
       " 'flag': dtype('O'),\n",
       " 'possible_hpo_features': dtype('O'),\n",
       " 'active_hpo_features': dtype('O')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(le.columns, le.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40257b15-bd6e-49ab-b7f1-e51529f2072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = pd.read_csv('diagnoses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c52d45cf-9c31-4c52-a9f3-c807421c50a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_id': dtype('int64'),\n",
       " 'subject_id': dtype('int64'),\n",
       " 'hadm_id': dtype('int64'),\n",
       " 'seq_num': dtype('int64'),\n",
       " 'icd9_code': dtype('O'),\n",
       " 'icd10_codes': dtype('O'),\n",
       " 'hpo_features': dtype('O')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(di.columns, di.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4176727-3f53-4307-86a6-cf90913f5626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph_Machine_Learning.ipynb  diagnoses.csv\n",
      "K-means_clustering.ipynb      lab_events.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a1412-712e-40ab-afaf-d1702714a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"facebook_combined.txt\", create_using = nx.Graph(), nodetype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5a155-28da-4488-a45e-6db08a9f397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e957a-75c8-4fbe-9df6-e02513fa3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_pos = nx.spring_layout(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087a155-d682-41c0-971a-431af1c72d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "nx.draw_networkx(G, pos=spring_pos, node_color=default_node_color, edge_color=default_edge_color, with_labels=False, node_size=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9b70f-62d9-466f-907c-2c7cb52523e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_metric(G, dct, spring_pos):\n",
    "  \"\"\" draw the graph G using the layout spring_pos.\n",
    "      The top 10 nodes w.r.t. values in the dictionary dct\n",
    "      are enhanced in the visualization \"\"\"\n",
    "  top = 10\n",
    "  max_nodes =  sorted(dct.items(), key = lambda v: -v[1])[:top]\n",
    "  \n",
    "  max_keys = [key for key,_ in max_nodes]\n",
    "  max_vals = [val*300 for _, val in max_nodes]\n",
    "\n",
    "  plt.axis(\"off\")\n",
    "  \n",
    "  nx.draw_networkx(G, \n",
    "                   pos=spring_pos, \n",
    "                   cmap='Blues', \n",
    "                   edge_color=default_edge_color,\n",
    "                   node_color=default_node_color, \n",
    "                   node_size=3,\n",
    "                   alpha=0.4, \n",
    "                   with_labels=False)\n",
    "  \n",
    "  nx.draw_networkx_nodes(G, \n",
    "                         pos=spring_pos, \n",
    "                         nodelist=max_keys, \n",
    "                         node_color=enhanced_edge_color,\n",
    "                         node_size=max_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba8ff5-747d-4b4c-bcbc-e8ad8057e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweenness centrality\n",
    "bC = nx.betweenness_centrality(G)\n",
    "np.mean(list(bC.values()))\n",
    "draw_metric(G,bC,spring_pos)\n",
    "# global efficiency\n",
    "gE = nx.global_efficiency(G)\n",
    "print(gE)\n",
    "# average clustering\n",
    "aC = nx.average_clustering(G)\n",
    "print(aC)\n",
    "# degree centrality\n",
    "deg_C = nx.degree_centrality(G)\n",
    "np.mean(list(deg_C.values()))\n",
    "draw_metric(G,deg_C,spring_pos)\n",
    "# closeness centrality\n",
    "clos_C = nx.closeness_centrality(G)\n",
    "np.mean(list(clos_C.values()))\n",
    "draw_metric(G,clos_C,spring_pos)\n",
    "# assortativity\n",
    "assortativity = nx.degree_pearson_correlation_coefficient(G)\n",
    "assortativity\n",
    "t = nx.transitivity(G)\n",
    "t\n",
    "#import networkx.algorithms.community as nx_comm\n",
    "#nx_comm.modularity(G, nx_comm.label_propagation_communities(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd12a48-1074-43d5-aa28-ffd4f214548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "\n",
    "parts = community.best_partition(G)\n",
    "values = [parts.get(node) for node in G.nodes()]\n",
    "\n",
    "for node in ego_nodes:\n",
    "  print(node, \"is in community number\", parts.get(node))\n",
    "  \n",
    "n_sizes = [5]*len(G.nodes())\n",
    "for node in ego_nodes:\n",
    "  n_sizes[node] = 250\n",
    "\n",
    "plt.axis(\"off\")\n",
    "nx.draw_networkx(G, pos=spring_pos, cmap=plt.get_cmap(\"Blues\"), edge_color=default_edge_color, node_color=values, node_size=n_sizes, with_labels=False)\n",
    "\n",
    "# enhance color and size of the ego-nodes\n",
    "nodes = nx.draw_networkx_nodes(G,spring_pos,ego_nodes,node_color=[parts.get(node) for node in ego_nodes])\n",
    "nodes.set_edgecolor(enhanced_node_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174cca2-8d27-468f-86a1-3944d774010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_colors = [0] * G0.number_of_nodes()\n",
    "count = 0\n",
    "for key in circles:\n",
    "  circle = circles[key]\n",
    "  for node in circle:\n",
    "    if node < G0.number_of_nodes():\n",
    "      node_colors[node] = count\n",
    "  count += 1\n",
    "\n",
    "nx.draw_networkx(G0, pos=pos_G0, with_labels=False, node_size=35, node_color=node_colors, edge_color=default_edge_color)\n",
    "parts = community.best_partition(G0)\n",
    "values = [parts.get(node) for node in G0.nodes()]\n",
    "\n",
    "plt.axis(\"off\")\n",
    "nx.draw_networkx(G0, pos=pos_G0, cmap=plt.get_cmap(\"Blues\"), edge_color=default_edge_color, node_color=values, node_size=35, with_labels=False)\n",
    "\n",
    "set(parts.values())\n",
    "len(circles)\n",
    "\n",
    "for i in circles:\n",
    "  for j in circles:\n",
    "    if i != j:\n",
    "      for n1 in circles[i]:\n",
    "        for n2 in circles[j]:\n",
    "          if n1 == n2:\n",
    "            print(n1, 'present in ',i,'found in', j)\n",
    "            assert(False)\n",
    "#@title  \n",
    "nx.average_shortest_path_length(G0)\n",
    "nx.global_efficiency(G0)\n",
    "nx.average_clustering(G0)\n",
    "\n",
    "np.mean(list(nx.betweenness_centrality(G0).values()))\n",
    "np.mean(list(nx.closeness_centrality(G0).values()))\n",
    "np.mean(list(nx.degree_centrality(G0).values()))\n",
    "nx.degree_pearson_correlation_coefficient(G)\n",
    "nx.transitivity(G)\n",
    "\n",
    "import networkx.algorithms.community as nx_comm\n",
    "nx_comm.modularity(G, nx_comm.label_propagation_communities(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c91ac1-459e-4cda-9ead-b21974243e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_file_name = \"feature_map.txt\"\n",
    "feature_index = {}  #numeric index to name\n",
    "inverted_feature_index = {} #name to numeric index\n",
    "network = nx.Graph()\n",
    "\n",
    "def parse_featname_line(line):\n",
    "  \"\"\" used to parse each line of the files containing feature names \"\"\"\n",
    "  line = line[(line.find(' '))+1:]  # chop first field\n",
    "  split = line.split(';')\n",
    "  name = ';'.join(split[:-1]) # feature name\n",
    "  index = int(split[-1].split(\" \")[-1]) #feature index\n",
    "  return index, name\n",
    "\n",
    "def load_features():\n",
    "  \"\"\" \n",
    "  parse each ego-network and creates two dictionaries:\n",
    "      - feature_index: maps numeric indices to names\n",
    "      - inverted_feature_index: maps names to numeric indices\n",
    "  \"\"\"\n",
    "  import glob\n",
    "  feat_file_name = 'tmp.txt'\n",
    "  # may need to build the index first\n",
    "  if not os.path.exists(feat_file_name):\n",
    "      feat_index = {}\n",
    "      # build the index from data/*.featnames files\n",
    "      featname_files = glob.iglob(\"facebook/*.featnames\")\n",
    "      for featname_file_name in featname_files:\n",
    "          featname_file = open(featname_file_name, 'r')\n",
    "          for line in featname_file:\n",
    "              # example line:\n",
    "              # 0 birthday;anonymized feature 376\n",
    "              index, name = parse_featname_line(line)\n",
    "              feat_index[index] = name\n",
    "          featname_file.close()\n",
    "      keys = feat_index.keys()\n",
    "      keys = sorted(keys)\n",
    "      out = open(feat_file_name,'w')\n",
    "      for key in keys:\n",
    "          out.write(\"%d %s\\n\" % (key, feat_index[key]))\n",
    "      out.close()\n",
    "\n",
    "  index_file = open(feat_file_name,'r')\n",
    "  for line in index_file:\n",
    "      split = line.strip().split(' ')\n",
    "      key = int(split[0])\n",
    "      val = split[1]\n",
    "      feature_index[key] = val\n",
    "  index_file.close()\n",
    "\n",
    "  for key in feature_index.keys():\n",
    "      val = feature_index[key]\n",
    "      inverted_feature_index[val] = key\n",
    "\n",
    "def parse_nodes(network, ego_nodes):\n",
    "  \"\"\"\n",
    "  for each nodes in the network assign the corresponding features \n",
    "  previously loaded using the load_features function\n",
    "  \"\"\"\n",
    "  # parse each node\n",
    "  for node_id in ego_nodes:\n",
    "      featname_file = open(f'facebook/{node_id}.featnames','r')\n",
    "      feat_file     = open(f'facebook/{node_id}.feat','r')\n",
    "      egofeat_file  = open(f'facebook/{node_id}.egofeat','r')\n",
    "      edge_file     = open(f'facebook/{node_id}.edges','r')\n",
    "\n",
    "      ego_features = [int(x) for x in egofeat_file.readline().split(' ')]\n",
    "\n",
    "      # Add ego node features\n",
    "      network.nodes[node_id]['features'] = np.zeros(len(feature_index))\n",
    "      \n",
    "      # parse ego node\n",
    "      i = 0\n",
    "      for line in featname_file:\n",
    "          key, val = parse_featname_line(line)\n",
    "          # Update feature value if necessary\n",
    "          if ego_features[i] + 1 > network.nodes[node_id]['features'][key]:\n",
    "              network.nodes[node_id]['features'][key] = ego_features[i] + 1\n",
    "          i += 1\n",
    "\n",
    "      # parse neighboring nodes\n",
    "      for line in feat_file:\n",
    "          featname_file.seek(0)\n",
    "          split = [int(x) for x in line.split(' ')]\n",
    "          node_id = split[0]\n",
    "          features = split[1:]\n",
    "\n",
    "          # Add node features\n",
    "          network.nodes[node_id]['features'] = np.zeros(len(feature_index))\n",
    "\n",
    "          i = 0\n",
    "          for line in featname_file:\n",
    "              key, val = parse_featname_line(line)\n",
    "              # Update feature value if necessary\n",
    "              if features[i] + 1 > network.nodes[node_id]['features'][key]:\n",
    "                  network.nodes[node_id]['features'][key] = features[i] + 1\n",
    "              i += 1\n",
    "          \n",
    "      featname_file.close()\n",
    "      feat_file.close()\n",
    "      egofeat_file.close()\n",
    "      edge_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c001004-1f65-428c-8d02-3e1f4acabe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_features()\n",
    "parse_nodes(G, ego_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05519732-46b2-4ddb-b3ac-bad884297621",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd8af8-6abb-45ec-9663-3b423830d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph import StellarGraph\n",
    "\n",
    "edgeSplitter = EdgeSplitter(G) \n",
    "graph_test, samples_test, labels_test = edgeSplitter.train_test_split(p=0.1, method=\"global\", seed=24)\n",
    "\n",
    "edgeSplitter = EdgeSplitter(graph_test, G) \n",
    "graph_train, samples_train, labels_train = edgeSplitter.train_test_split(p=0.1, method=\"global\", seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddc34d-5487-4af7-bbaf-ce2fc51be12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder \n",
    "from stellargraph.data import EdgeSplitter \n",
    "\n",
    "node2vec = Node2Vec(graph_train) \n",
    "model = node2vec.fit() \n",
    "edges_embs = HadamardEmbedder(keyed_vectors=model.wv) \n",
    "train_embeddings = [edges_embs[str(x[0]),str(x[1])] for x in samples_train]\n",
    "\n",
    "edges_embs = HadamardEmbedder(keyed_vectors=model.wv) \n",
    "test_embeddings = [edges_embs[str(x[0]),str(x[1])] for x in samples_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cf625-df56-47fe-86cb-94fb45b40fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10) \n",
    "rf.fit(train_embeddings, labels_train); \n",
    " \n",
    "y_pred = rf.predict(test_embeddings) \n",
    "print('Precision:', metrics.precision_score(labels_test, y_pred)) \n",
    "print('Recall:', metrics.recall_score(labels_test, y_pred)) \n",
    "print('F1-Score:', metrics.f1_score(labels_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e2e04-85b3-46a6-b45d-a7f4812432da",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = np.eye(graph_train.number_of_nodes())\n",
    "fake_features = {n:eye[n] for n in G.nodes()}\n",
    "nx.set_node_attributes(graph_train, fake_features, \"fake\")\n",
    "\n",
    "eye = np.eye(graph_test.number_of_nodes())\n",
    "fake_features = {n:eye[n] for n in G.nodes()}\n",
    "nx.set_node_attributes(graph_test, fake_features, \"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3249689-525e-4f5c-bed1-c84bfd868528",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_train.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738fe92-cceb-4790-9a51-ccd7a5de8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "\n",
    "batch_size = 64\n",
    "num_samples = [4, 4]\n",
    "\n",
    "sg_graph_train = StellarGraph.from_networkx(graph_train, node_features=\"fake\")\n",
    "sg_graph_test = StellarGraph.from_networkx(graph_test, node_features=\"fake\")\n",
    "\n",
    "train_gen = GraphSAGELinkGenerator(sg_graph_train, batch_size, num_samples)\n",
    "train_flow = train_gen.flow(samples_train, labels_train, shuffle=True, seed=24)\n",
    "\n",
    "test_gen = GraphSAGELinkGenerator(sg_graph_test, batch_size, num_samples)\n",
    "test_flow = test_gen.flow(samples_test, labels_test, seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6363183-3232-4c0f-a5d1-6fe7d08bfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.layer import GraphSAGE, link_classification\n",
    "from tensorflow import keras\n",
    "\n",
    "layer_sizes = [20, 20]\n",
    "graphsage = GraphSAGE(\n",
    "    layer_sizes=layer_sizes, generator=train_gen, bias=True, dropout=0.3\n",
    ")\n",
    "\n",
    "x_inp, x_out = graphsage.in_out_tensors()\n",
    "\n",
    "prediction = link_classification(\n",
    "    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    ")(x_out)\n",
    "\n",
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=keras.losses.mse,\n",
    "    metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb42f3-1ea0-49a7-90f7-f5a3ea5cd6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(train_flow, epochs=epochs, validation_data=test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb3134-8391-4b4e-8b04-1a2fa9e9a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "y_pred = np.round(model.predict(train_flow)).flatten()\n",
    "print('Precision:', metrics.precision_score(labels_train, y_pred)) \n",
    "print('Recall:', metrics.recall_score(labels_train, y_pred)) \n",
    "print('F1-Score:', metrics.f1_score(labels_train, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ce317-63fa-457e-a338-8f4b037d8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(model.predict(test_flow)).flatten()\n",
    "print('Precision:', metrics.precision_score(labels_test, y_pred)) \n",
    "print('Recall:', metrics.recall_score(labels_test, y_pred)) \n",
    "print('F1-Score:', metrics.f1_score(labels_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b679be-22db-4b2d-839a-cd640a842a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_graph_train = StellarGraph.from_networkx(graph_train, node_features=\"features\")\n",
    "sg_graph_test = StellarGraph.from_networkx(graph_test, node_features=\"features\")\n",
    "\n",
    "train_gen = GraphSAGELinkGenerator(sg_graph_train, batch_size, num_samples)\n",
    "train_flow = train_gen.flow(samples_train, labels_train, shuffle=True, seed=24)\n",
    "\n",
    "test_gen = GraphSAGELinkGenerator(sg_graph_test, batch_size, num_samples)\n",
    "test_flow = test_gen.flow(samples_test, labels_test, seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035cd2e2-30d7-4059-a21f-bb9fb90a48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [20, 20]\n",
    "graphsage = GraphSAGE(\n",
    "    layer_sizes=layer_sizes, generator=train_gen, bias=True, dropout=0.3\n",
    ")\n",
    "\n",
    "x_inp, x_out = graphsage.in_out_tensors()\n",
    "\n",
    "prediction = link_classification(\n",
    "    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    ")(x_out)\n",
    "\n",
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=keras.losses.mse,\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(train_flow, epochs=epochs, validation_data=test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb79907-6690-4a75-8a1d-441f6a6ec558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "y_pred = np.round(model.predict(train_flow)).flatten()\n",
    "print('Precision:', metrics.precision_score(labels_train, y_pred)) \n",
    "print('Recall:', metrics.recall_score(labels_train, y_pred)) \n",
    "print('F1-Score:', metrics.f1_score(labels_train, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293d6af-8663-4f54-9536-ab3f0bf4e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(model.predict(test_flow)).flatten()\n",
    "print('Precision:', metrics.precision_score(labels_test, y_pred)) \n",
    "print('Recall:', metrics.recall_score(labels_test, y_pred)) \n",
    "print('F1-Score:', metrics.f1_score(labels_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaec69a-0639-4c63-91ef-cb729e05d6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9f83d-347d-4638-9300-f40d3eea1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "\n",
    "def get_shortest_path(G,u,v):\n",
    "  \"\"\" return the shortest path length between u,v \n",
    "      in the graph without the edge (u,v) \"\"\"\n",
    "  removed = False\n",
    "  if G.has_edge(u,v):\n",
    "    removed = True\n",
    "    G.remove_edge(u,v) # temporary remove edge\n",
    "  \n",
    "  try:\n",
    "    sp = len(nx.shortest_path(G, u, v))\n",
    "  except:\n",
    "    sp = 0\n",
    "\n",
    "  if removed:\n",
    "    G.add_edge(u,v) # add back the edge if it was removed\n",
    "\n",
    "  return sp\n",
    "\n",
    "def get_hc_features(G, samples_edges, labels):\n",
    "  # precompute metrics\n",
    "  centralities = nx.degree_centrality(G)\n",
    "  parts = community.best_partition(G)\n",
    "  \n",
    "  feats = []\n",
    "  for (u,v),l in zip(samples_edges, labels):\n",
    "    shortest_path = get_shortest_path(G, u, v)\n",
    "    j_coefficient = next(nx.jaccard_coefficient(G, ebunch=[(u, v)]))[-1]\n",
    "    u_centrality = centralities[u]\n",
    "    v_centrality = centralities[v]\n",
    "    u_community = parts.get(u)\n",
    "    v_community = parts.get(v)\n",
    "    # add the feature vector\n",
    "    feats += [[shortest_path, j_coefficient, u_centrality, v_centrality]]\n",
    "  return feats\n",
    "\n",
    "feat_train = get_hc_features(graph_train, samples_train, labels_train)\n",
    "feat_test = get_hc_features(graph_test, samples_test, labels_test)\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10) \n",
    "rf.fit(feat_train, labels_train); \n",
    " \n",
    "y_pred = rf.predict(feat_test) \n",
    "print('Precision:', metrics.precision_score(labels_test, y_pred)) \n",
    "print('Recall:', metrics.recall_score(labels_test, y_pred)) \n",
    "print('F1-Score:', metrics.f1_score(labels_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56cb571-d2c4-4fe4-a32d-08130b87f53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
